# ğŸ  Application DVF - Analyse des Valeurs FonciÃ¨res

Application Streamlit pour analyser les donnÃ©es de valeurs fonciÃ¨res stockÃ©es dans Snowflake.

## ğŸ“‹ FonctionnalitÃ©s

- Recherche par commune et rue
- Filtrage par type de bien (Maison, Appartement, Local commercial)
- Statistiques dÃ©taillÃ©es (nombre de transactions, prix moyen, prix mÃ©dian, surface moyenne)
- Graphiques interactifs :
  - Ã‰volution des prix dans le temps
  - Distribution des prix
  - Prix moyen par type de bien
- Tableau dÃ©taillÃ© des transactions
- Export des donnÃ©es en CSV

## ğŸš€ Installation

1. Cloner le repository

```bash
git clone <url-du-repo>
cd streamlit-dvf
```

2. CrÃ©er un environnement virtuel

```bash
python -m venv venv
source venv/bin/activate  # Sur Windows: venv\Scripts\activate
```

3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

4. Configurer la connexion Snowflake

Copier le fichier d'exemple et remplir avec vos identifiants :

```bash
cp .streamlit/secrets.toml.example .streamlit/secrets.toml
```

Puis Ã©diter `.streamlit/secrets.toml` avec vos informations Snowflake :

```toml
[snowflake]
user = "votre_username"
password = "votre_password"
account = "votre_account"
warehouse = "votre_warehouse"
database = "VALFONC_ANALYTICS"
schema = "GOLD"
```

## ğŸ¯ Utilisation

Lancer l'application :

```bash
streamlit run app.py
```

L'application sera accessible Ã  l'adresse : http://localhost:8501

## ğŸ“Š Structure des donnÃ©es

L'application utilise le semantic layer `VALFONC_ANALYTICS.GOLD.DVF` qui contient :

- **DIM_ADDRESS** : Adresses avec rue, code postal, commune
- **DIM_COMMUNE** : Communes et dÃ©partements
- **DIM_TYPE_LOCAL** : Types de locaux (maison, appartement, etc.)
- **FACT_MUTATION** : Transactions immobiliÃ¨res avec valeur fonciÃ¨re, date, surfaces

## ğŸ› ï¸ Technologies utilisÃ©es

- **Streamlit** : Framework web pour l'interface
- **Snowflake** : Base de donnÃ©es cloud
- **Pandas** : Manipulation de donnÃ©es
- **Plotly** : Visualisations interactives

## ğŸ“ Notes

- Les donnÃ©es sont mises en cache pour amÃ©liorer les performances
- La limite de rÃ©sultats est fixÃ©e Ã  5000 transactions par requÃªte
- L'export CSV contient toutes les colonnes de donnÃ©es brutes
